{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25a89497",
   "metadata": {},
   "source": [
    "# Experimenting with MongoDB Docker container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbc04b3",
   "metadata": {},
   "source": [
    "## Set up of Docker container on local machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ea950",
   "metadata": {},
   "source": [
    "For this experiment I created a local folder with the following structure on my machine. <br>\n",
    "\n",
    "```\n",
    "docker_test\n",
    "    └── data\n",
    "        ├── csv_data\n",
    "        │   ├── 1652951631.csv\n",
    "        │   ├── 1652951755.csv\n",
    "        │   ├── 1652951877.csv\n",
    "        │   ├── 1652951992.csv\n",
    "        │   ├── 1652952112.csv\n",
    "        │   ├── 1652952240.csv\n",
    "        │   ├── 1652952353.csv\n",
    "        │   ├── 1652952472.csv\n",
    "        │   ├── 1652952598.csv\n",
    "        │   ├── 1652952711.csv\n",
    "        │   ├── 1652952837.csv\n",
    "        │   ├── 1652952961.csv\n",
    "        │   ├── 1652953072.csv\n",
    "        │   ├── 1652953199.csv\n",
    "        │   ├── 1652953311.csv\n",
    "        │   ├── 1652953435.csv\n",
    "        │   ├── 1652953552.csv\n",
    "        │   └── 1652953679.csv\n",
    "        └── mongo_db\n",
    "```\n",
    "\n",
    "- The `csv_data` folder contains some .csv files which I downloaded from seneca\n",
    "- The `mongo_db` folder is where the mongo_db should be stored in the end locally, so it will not be deleted after we stop the container (aka volume for this docker container)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fc2353",
   "metadata": {},
   "source": [
    "In order to create and run a Docker container with MongoDB I changed my working directory into the `docker_test` folder and ran the following command in the terminal:\n",
    "```\n",
    "docker run -d -p 27017:27017 -v `pwd`/data/mongo_db:/data/db --name mongo_db mongo   \n",
    "```\n",
    "Now the container should be running in the background (you can check with ```docker container ls```)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2930bb68",
   "metadata": {},
   "source": [
    "## Python code to connect to MongoDB and insert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81440c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from pymongo import MongoClient\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb8f4914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client connects to \"localhost\" by default \n",
    "client = MongoClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bc02aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new client\n",
    "db = client['TravelDashboard']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d66116",
   "metadata": {},
   "source": [
    "### Test whether we can add documents which will be persisted even after stopping and restarting the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc1676b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is just a random example of a docuemnt which could be entered\n",
    "courses = {'title': 'Data Science',\n",
    "         'lecturer': {\n",
    "         'name': 'Markus Löcher',\n",
    "         'department': 'Math',\n",
    "         'status': 'Professor'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6385ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x112412190>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.courses.insert_one(courses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d83d6a",
   "metadata": {},
   "source": [
    "In between these steps I stopped an restarted the docker container:\n",
    "```\n",
    "docker stop mongo_db\n",
    "docker restart mongo_db\n",
    "```\n",
    "Now let's check if the the entry is still there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b4217ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('62a8684d3138824bd05e4e39'),\n",
      " 'lecturer': {'department': 'Math',\n",
      "              'name': 'Markus Löcher',\n",
      "              'status': 'Professor'},\n",
      " 'title': 'Data Science'}\n"
     ]
    }
   ],
   "source": [
    "# Print all documents\n",
    "cursor = db.courses.find()\n",
    "\n",
    "for document in cursor:\n",
    "    pprint(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24f3449",
   "metadata": {},
   "source": [
    "The entry is still there :) That's good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37590090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets drop the courses collection\n",
    "db.courses.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5cb6d5",
   "metadata": {},
   "source": [
    "### Add all sample .csv files to the MongoDB using python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5cfbdd04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/philippheitmann/Desktop/docker_test'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check current directory where notebook is located\n",
    "import os \n",
    "import glob\n",
    "os.path.abspath(\"\") # in python it should not be (\"\"), but (__file__) !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4be19b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get path of all .csv files in csv_data folder\n",
    "all_files = glob.glob(os.path.join(os.path.abspath(\"\"), \"data\", \"csv_data\", \"*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40310901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(all_files[0], index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3eceb7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store csv as list of dictonaries (each row/flight will be one dict)\n",
    "df_dict = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d4d009a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x11ebaa0d0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input the lsit of dicts into MongoDB\n",
    "db.travel_data.insert_many(df_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d703d4ab",
   "metadata": {},
   "source": [
    "In between these steps I stopped an restarted the docker container:\n",
    "```\n",
    "docker stop mongo_db\n",
    "docker restart mongo_db\n",
    "```\n",
    "Now let's check if the the entries are still there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "30dbf84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3327"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of documents in MongoDB collection travel_data\n",
    "db.travel_data.count_documents({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9d2d74ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if number of documents is equal to number of rows from the dataframe\n",
    "db.travel_data.count_documents({})==df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd72713",
   "metadata": {},
   "source": [
    "### Insert all csv files in the mongodb\n",
    "Great :) Now lets include all documents in the csv_folder into the mongoDB collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d7f28e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's drop the collection \n",
    "db.travel_data.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b9626a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 35M\tdata/mongo_db\r\n"
     ]
    }
   ],
   "source": [
    "# Lets see how big the mongo folder is before including the documents\n",
    "!du -hs data/mongo_db     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ae316f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.54 s, sys: 201 ms, total: 5.74 s\n",
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Loop over all files in csv_data folder and insert them into the MongoDB\n",
    "for file in all_files:\n",
    "    db.travel_data.insert_many(pd.read_csv(file, index_col=0).to_dict(orient='records'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0fde4f",
   "metadata": {},
   "source": [
    "So for 10 .csv files it took me ~12 seconds. In our seneca folder there are more than 16k files already :P "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3c17f3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.444444444444445"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we want to include all csv files into mongodb we will need 4.5 hours (for the current number of files)\n",
    "16_000/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5231ca2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 56M\tdata/mongo_db\r\n"
     ]
    }
   ],
   "source": [
    "# Lets see how big the mongo folder is after including the documents\n",
    "!du -hs data/mongo_db  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cfd063",
   "metadata": {},
   "source": [
    "So at least for this sample it was ~ 2MB per .csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8a9e606b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So if we include all .csv files (current status: 16k) we will need 32GB of disk space on our local machine \n",
    "2*16_000/1000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
